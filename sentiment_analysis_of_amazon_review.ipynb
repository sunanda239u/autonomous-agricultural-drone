{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunanda239u/autonomous-agricultural-drone/blob/main/sentiment_analysis_of_amazon_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "all imports"
      ],
      "metadata": {
        "id": "kkbjqSU-ZXVN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDKNZs6wnC_M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import bz2\n",
        "import os\n",
        "\n",
        "import re\n",
        "import gc\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.python.keras import models, layers, optimizers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ydWlKuVaZU08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "created a functin to assign labels and comments to the given dataset"
      ],
      "metadata": {
        "id": "POrAOs23ZVvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_labels_and_comments(file):\n",
        "    labels = []\n",
        "    comments = []\n",
        "    for line in bz2.BZ2File(file):\n",
        "        x = line.decode(\"utf-8\")\n",
        "        labels.append(int(x[9]) - 1)\n",
        "        comments.append(x[10:].strip())\n",
        "    return np.array(labels), comments"
      ],
      "metadata": {
        "id": "A3bownusnVLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "assigned labels and dataset to both test and train dataset"
      ],
      "metadata": {
        "id": "qTyH_z0wZ2fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " test_labels, test_comments = assign_labels_and_comments('/content/test.ft.txt.bz2')"
      ],
      "metadata": {
        "id": "J5gZAIkpx2sX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "fb6a4c57-dd23-49e0-fa37-86bcc97797bd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-efe9fdf0fa19>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_comments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_labels_and_comments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test.ft.txt.bz2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'assign_labels_and_comments' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels, train_comments = assign_labels_and_comments('/content/train.ft.txt.bz2')"
      ],
      "metadata": {
        "id": "vKpKzU75nXI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to preprocess the given dataset"
      ],
      "metadata": {
        "id": "LWGvsiDgZ_9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def processed_comments(texts):\n",
        "    processed_comments = []\n",
        "    for text in texts:\n",
        "        lower = text.lower()\n",
        "        no_punctuation = not_alphanumeric.sub(r' ', lower)\n",
        "        no_non_ascii = not_ascii.sub(r'', no_punctuation)\n",
        "        processed_comments.append(no_non_ascii)\n",
        "    return processed_comments"
      ],
      "metadata": {
        "id": "uV0x9_xK05Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7O6BBapM1KaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_alphanumeric = re.compile(r'[\\W]')\n",
        "not_ascii = re.compile(r'[^a-z0-1\\s]')"
      ],
      "metadata": {
        "id": "EHG-BxqW0dOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessed both the dataset"
      ],
      "metadata": {
        "id": "B48BcflvaIb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_comments = processed_comments(test_comments)"
      ],
      "metadata": {
        "id": "chUGBNsO1LmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_comments = processed_comments(train_comments)"
      ],
      "metadata": {
        "id": "vNTMEBHZ1OFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "spliting the train dataset into train and validation dataset"
      ],
      "metadata": {
        "id": "ufDLJPF2aPD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_comments, val_comments, train_labels, val_labels = train_test_split(train_comments, train_labels, random_state=42, test_size=0.2)"
      ],
      "metadata": {
        "id": "rIpOKTUx2yK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting features to tokens"
      ],
      "metadata": {
        "id": "OCNhBC_qaclt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maximum_features = 14000\n",
        "tokenizer = Tokenizer(num_words=maximum_features)\n",
        "tokenizer.fit_on_texts(train_comments)\n",
        "train_comments = tokenizer.texts_to_sequences(train_comments)\n",
        "val_comments = tokenizer.texts_to_sequences(val_comments)\n",
        "test_comments = tokenizer.texts_to_sequences(test_comments)"
      ],
      "metadata": {
        "id": "TXYcKD-k3ld3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maximum_length = max(len(train_ex) for train_ex in train_comments)\n",
        "train_comments_pad = pad_sequences(train_comments, maxlen=maximum_length)\n",
        "val_comments_pad = pad_sequences(val_comments, maxlen=maximum_length)\n",
        "test_comments_pad = pad_sequences(test_comments, maxlen=maximum_length)\n",
        "del train_comments, val_comments, test_comments\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "wLBZRUoI3p5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training CNN model"
      ],
      "metadata": {
        "id": "pE9cFObgahjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_model():\n",
        "    sequences = layers.Input(shape=(maximum_length,))\n",
        "    embedded = layers.Embedding(maximum_features, 64)(sequences)\n",
        "    x = layers.Conv1D(64, 3, activation='relu')(embedded)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool1D(3)(x)\n",
        "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool1D(5)(x)\n",
        "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
        "    x = layers.GlobalMaxPool1D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(100, activation='relu')(x)\n",
        "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = models.Model(inputs=sequences, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer='rmsprop',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['binary_accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = cnn_model()"
      ],
      "metadata": {
        "id": "TdmjKvry3t51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_comments_pad,\n",
        "    train_labels,\n",
        "    batch_size=128,\n",
        "    epochs=3,\n",
        "    validation_data=(val_comments_pad, val_labels))"
      ],
      "metadata": {
        "id": "ICftKQdG3wdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finding accuracy of CNN model"
      ],
      "metadata": {
        "id": "1HL4Zy6Ialox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_preds = model.predict(test_comments_pad)\n",
        "\n",
        "accuracy_cnn = accuracy_score(test_labels, 1 * (cnn_preds > 0.5))\n",
        "f1_cnn = f1_score(test_labels, 1 * (cnn_preds > 0.5))\n",
        "rocauc_cnn = roc_auc_score(test_labels, cnn_preds)\n",
        "\n",
        "print('Accuracy score of the CNN Model: {:0.3}'.format(accuracy_cnn))\n",
        "print('F1 score of the CNN Model: {:0.3}'.format(f1_cnn))\n",
        "print('ROC AUC score of the CNN Model: {:0.3}'.format(rocauc_cnn))"
      ],
      "metadata": {
        "id": "2yeghk3I3xA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "gURQoMP530XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating RNN model"
      ],
      "metadata": {
        "id": "WnVCoOAfapT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rnn_model():\n",
        "    sequences = layers.Input(shape=(maximum_length,))\n",
        "    embedded = layers.Embedding(maximum_features, 64)(sequences)\n",
        "    x = layers.CuDNNGRU(128, return_sequences=True)(embedded)\n",
        "    x = layers.CuDNNGRU(128)(x)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    x = layers.Dense(100, activation='relu')(x)\n",
        "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = models.Model(inputs=sequences, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer='rmsprop',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['binary_accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "rnn_model = rnn_model()"
      ],
      "metadata": {
        "id": "dSj6BNpF3441"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.fit(train_comments_pad,\n",
        "    train_labels,\n",
        "    batch_size=128,\n",
        "    epochs=3,\n",
        "    validation_data=(val_comments_pad, val_labels))"
      ],
      "metadata": {
        "id": "z8ANEZ3n3_Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding accuracy of RNN model"
      ],
      "metadata": {
        "id": "vBuv1rpbavVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_preds = rnn_model.predict(test_comments_pad)\n",
        "\n",
        "accuracy_rnn = accuracy_score(test_labels, 1 * (rnn_preds > 0.5))\n",
        "f1_rnn = f1_score(test_labels, 1 * (rnn_preds > 0.5))\n",
        "rocauc_rnn = roc_auc_score(test_labels, rnn_preds)\n",
        "\n",
        "print('Accuracy score of the RNN Model: {:0.3}'.format(accuracy_rnn))\n",
        "print('F1 score of the RNN Model: {:0.3}'.format(f1_rnn))\n",
        "print('ROC AUC score of the RNN Model: {:0.3}'.format(rocauc_rnn))"
      ],
      "metadata": {
        "id": "uIfsuL_64WI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_acc_dict = {}\n",
        "model_f1_dict = {}\n",
        "model_rocauc_dict = {}"
      ],
      "metadata": {
        "id": "eon5xHgcFmPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_acc_dict['Convolutional_Neural_Network'] = accuracy_cnn\n",
        "model_f1_dict['Convolutional_Neural_Network'] = f1_cnn\n",
        "model_rocauc_dict['Convolutional_Neural_Network'] = rocauc_cnn\n",
        "\n",
        "model_acc_dict['Recurrent_Neural_Network'] = accuracy_rnn\n",
        "model_f1_dict['Recurrent_Neural_Network'] = f1_rnn\n",
        "model_rocauc_dict['Recurrent_Neural_Network'] = rocauc_rnn"
      ],
      "metadata": {
        "id": "auoZ0C74FpNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "created 3 custom functions to display the comparison graph"
      ],
      "metadata": {
        "id": "EuBQ8x0eHBmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model_f1_scores(model_dict):\n",
        "    model_f1_scores_df = pd.DataFrame(columns=['Model', 'F1 Score'])\n",
        "    model_f1_scores_df['Model'] = model_dict.keys()\n",
        "    model_f1_scores_df['F1 Score'] = model_dict.values()\n",
        "    model_f1_scores_df.sort_values('F1 Score', inplace=True, ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(6,4),)\n",
        "    plt.ylabel(\"Models\", fontsize=16)\n",
        "    plt.xlabel(\"F1 Score\", fontsize=16)\n",
        "    plt.title(\"Model F1 Scores\", fontsize=22)\n",
        "    sns.barplot(y = pd.to_numeric(model_f1_scores_df['F1 Score']), x = model_f1_scores_df['Model'], palette='magma')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"The Models have the following F1 Scores:\")\n",
        "    print(f\"{model_f1_scores_df.iloc[:2, ]}\")"
      ],
      "metadata": {
        "id": "_77p7vwTFvoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model_accuracies(model_dict):\n",
        "    model_accuracies_df = pd.DataFrame(columns=['Model', 'Accuracy'])\n",
        "    model_accuracies_df['Model'] = model_dict.keys()\n",
        "    model_accuracies_df['Accuracy'] = model_dict.values()\n",
        "    model_accuracies_df.sort_values('Accuracy', inplace=True, ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(6,4),)\n",
        "    plt.ylabel(\"Models\", fontsize=16)\n",
        "    plt.xlabel(\"Accuracy\", fontsize=16)\n",
        "    plt.title(\"Model Accuracies\", fontsize=22)\n",
        "    sns.barplot(y = pd.to_numeric(model_accuracies_df['Accuracy']), x = model_accuracies_df['Model'], palette='magma')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"The Models have the following accuracies :\")\n",
        "    print(f\"{model_accuracies_df.iloc[:2, ]}\")"
      ],
      "metadata": {
        "id": "JxI8nqapF4v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model_rocauc_scores(model_dict):\n",
        "    model_rocauc_scores_df = pd.DataFrame(columns=['Model', 'ROC AUC'])\n",
        "    model_rocauc_scores_df['Model'] = model_dict.keys()\n",
        "    model_rocauc_scores_df['ROC AUC'] = model_dict.values()\n",
        "    model_rocauc_scores_df.sort_values('ROC AUC', inplace=True, ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(6,4),)\n",
        "    plt.ylabel(\"Models\", fontsize=16)\n",
        "    plt.xlabel(\"ROC AUC\", fontsize=16)\n",
        "    plt.title(\"Model ROC AUC\", fontsize=22)\n",
        "    sns.barplot(y = pd.to_numeric(model_rocauc_scores_df['ROC AUC']), x = model_rocauc_scores_df['Model'], palette='magma')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"The Models have the following ROC AUC Scores :\")\n",
        "    print(f\"{model_rocauc_scores_df.iloc[:2, ]}\")"
      ],
      "metadata": {
        "id": "LV65JUKPGv6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LVEwC4YcG7cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "called the functions to display the visual comparison"
      ],
      "metadata": {
        "id": "vcZWUoqZG7xX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model_accuracies(model_acc_dict)"
      ],
      "metadata": {
        "id": "LYUlSW3aG0Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model_f1_scores(model_f1_dict)"
      ],
      "metadata": {
        "id": "CdqlyiRaG4ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model_rocauc_scores(model_rocauc_dict)"
      ],
      "metadata": {
        "id": "wnAnhKzYG6at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h_hEaNKlZTXv"
      }
    }
  ]
}